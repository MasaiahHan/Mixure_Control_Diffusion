{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers import  ControlNetModel, EulerAncestralDiscreteScheduler\n",
    "from mixdiff import StableDiffusionCanvasControlnetPipeline\n",
    "from mixdiff.canvas_multicontrolnet import Text2ImageRegion\n",
    "import torch\n",
    "from PIL import Image\n",
    "\n",
    "# Creater scheduler and model (similar to StableDiffusionPipeline)\n",
    "controlnet_canny = ControlNetModel.from_pretrained(\"lllyasviel/sd-controlnet-canny\" \n",
    "                                            ).to(\"cuda\")\n",
    "# controlnet_pose = ControlNetModel.from_pretrained(\"lllyasviel/sd-controlnet-openpose\", \n",
    "#                                                    ).to(\"cuda\")\n",
    "\n",
    "\n",
    "scheduler = EulerAncestralDiscreteScheduler.from_pretrained(\"YOUR OWN SCHEDULER PATH\",subfolder=\"scheduler\")\n",
    "pipeline = StableDiffusionCanvasControlnetPipeline.from_pretrained(\"YOUR OWN SD CKPT PATH\",\n",
    "                                                                    scheduler=scheduler, use_auth_token=True,\n",
    "                                                                    \tcontrolnet=[\n",
    "    controlnet_canny,controlnet_canny,controlnet_canny,controlnet_canny,controlnet_canny,controlnet_canny,controlnet_canny,controlnet_canny,controlnet_canny\n",
    "\t],).to(\"cuda:0\")\n",
    "\n",
    "\n",
    "\n",
    "image1 = Image.open('YOUR OWN IMAGE PATH').crop((0,0,512,640))\n",
    "image2 = Image.open('YOUR OWN IMAGE PATH').crop((256,0,768,640))\n",
    "image3 = Image.open('YOUR OWN IMAGE PATH').crop((512,0,1024,640))\n",
    "image4 = Image.open('YOUR OWN IMAGE PATH').crop((0,384,512,1024))\n",
    "image5 = Image.open('YOUR OWN IMAGE PATH').crop((256,384,768,1024))\n",
    "image6 = Image.open('YOUR OWN IMAGE PATH').crop((512,384,1024,1024))\n",
    "image7 = Image.open('YOUR OWN IMAGE PATH').crop((0,768,512,1408))\n",
    "image8 = Image.open('YOUR OWN IMAGE PATH').crop((256,768,768,1408))\n",
    "image9 = Image.open('YOUR OWN IMAGE PATH').crop((512,768,1024,1408))\n",
    "\n",
    "\n",
    "\n",
    "main_prompt=\" YOUR OWN PROMPT \"\n",
    "\n",
    "image = pipeline(\n",
    "    canvas_height=1408,\n",
    "    canvas_width=1024,\n",
    "    regions=[\n",
    "        Text2ImageRegion(0, 640, 0, 512, guidance_scale=8,      # height first then width\n",
    "            prompt= f\"\" + main_prompt),\n",
    "        Text2ImageRegion(0, 640, 256, 768, guidance_scale=8,\n",
    "            prompt=  f\"\" + main_prompt),\n",
    "        Text2ImageRegion(0, 640, 512, 1024, guidance_scale=8,\n",
    "            prompt= f\"\" + main_prompt),\n",
    "        Text2ImageRegion(384, 1024, 0, 512, guidance_scale=8,      # height first then width\n",
    "            prompt= f\"\" + main_prompt),\n",
    "        Text2ImageRegion(384, 1024, 256, 768, guidance_scale=8,\n",
    "            prompt=  f\"\" + main_prompt),\n",
    "        Text2ImageRegion(384, 1024, 512, 1024, guidance_scale=8,\n",
    "            prompt=  f\"\" + main_prompt),\n",
    "        Text2ImageRegion(768, 1408, 0, 512, guidance_scale=8,      # height first then width\n",
    "            prompt= f\"\" + main_prompt),\n",
    "        Text2ImageRegion(768, 1024, 256, 768, guidance_scale=8,\n",
    "            prompt=  f\"\" + main_prompt),\n",
    "        Text2ImageRegion(768, 1024, 512, 1024, guidance_scale=8,\n",
    "            prompt=  f\"\" + main_prompt),\n",
    "    ],\n",
    "    image=[image1, image2,image3,image4,image5,image6,image7,image8,image9],    num_inference_steps=50,\n",
    "    seed=7178915308,\n",
    ")[\"sample\"][0]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
